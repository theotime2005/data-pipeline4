# üéØ Data Pipeline Iris - Architecture Dockeris√©e

## Vue d'ensemble

Pipeline complet **100% Dockeris√©** et orchestr√© avec **Docker Compose**, du pr√©traitement des donn√©es √† la pr√©diction via API REST.

### üìä Flux de donn√©es
```
iris.csv
   ‚Üì
[Preprocess Service] ‚Üí nettoie, normalise
   ‚Üì
[PostgreSQL] ‚Üí stocke iris_clean
   ‚Üì
[Training Service] ‚Üí Random Forest Regressor
   ‚Üì
[MLflow] ‚Üí enregistre mod√®le + m√©triques (MSE, R¬≤)
   ‚Üì
[API FastAPI] ‚Üí /predict ‚Üí pr√©dictions en temps r√©el
```

---

## üèóÔ∏è Architecture

### Services Docker Compose

| Service | R√¥le | Port | Technologie |
|---------|------|------|-------------|
| **db** | Base de donn√©es centrale | 5432 | PostgreSQL 16 |
| **mlflow** | Tracking exp√©riences & artefacts | 5000 | MLflow + Backend Postgres |
| **preprocess** | ETL (Extract ‚Üí Transform ‚Üí Load) | - | Python + Pandas + SQLAlchemy |
| **train** | ML Training avec enregistrement | - | Python + scikit-learn + MLflow |
| **api** | API de pr√©diction | 8000 | FastAPI + Uvicorn |
| **ui** | Interface web (UI + reverse proxy) | 3000 | Nginx alpine |

---

## üöÄ D√©marrage rapide

### 1Ô∏è‚É£ Lancer le pipeline complet

```bash
docker compose up --build
```

### 2Ô∏è‚É£ Acc√©der aux interfaces

- **UI Web** : http://localhost:3000 (interface pr√©diction via navigateur)
- **API Swagger** : http://localhost:8000/docs
- **MLflow UI** : http://localhost:5000

### 3Ô∏è‚É£ Tester la pr√©diction

Via API directe :
```bash
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{"sepal_width": 3.4}'
```

Via UI web (reverse proxy Nginx) :
```bash
curl -X POST "http://localhost:3000/api/predict" \
  -H "Content-Type: application/json" \
  -d '{"sepal_width": 3.4}'
```

---

## ‚úÖ Tests End‚Äëto‚Äëend

Un script d'int√©gration automatique est fourni : `scripts/e2e_test.sh`.
Il :
- rebuild la stack (`docker compose down -v && docker compose up --build -d`)
- attend que MLflow et l'API r√©pondent
- attend que `/predict` retourne 200 et affiche la r√©ponse

Ex√©cuter :

```bash
./scripts/e2e_test.sh
```

---

## üìã Services d√©taill√©s

### Preprocess
- Charge `iris.csv`
- Normalise les colonnes
- Supprime NA et doublons
- StandardScaler sur features num√©riques
- √âcrit dans PostgreSQL (table `iris_clean`)

### Training
- Entra√Æne `RandomForestRegressor`
- Target : `sepal_length` | Feature : `sepal_width`
- Enregistre mod√®le + m√©triques (MSE, R¬≤) dans MLflow

### API
- `GET /health` ‚Üí `{ "status": "ok" }`
- `POST /predict` ‚Üí pr√©diction `sepal_length` √† partir de `sepal_width`

### UI
- Interface web statique (HTML/CSS/JS) servie via Nginx
- Reverse proxy Nginx : `/api/*` ‚Üí `http://api:8000/`
- Permet requ√™tes depuis navigateur (CORS, preflight OPTIONS)
- Pr√©dictions accessibles via `http://localhost:3000`

---

## üîß Configuration (.env)

Fichier `.env` dans la racine (exemple) :

```env
POSTGRES_DB=irisdb
POSTGRES_USER=iris
POSTGRES_PASSWORD=irispass
POSTGRES_HOST=db
POSTGRES_PORT=5432

MLFLOW_TRACKING_URI=http://mlflow:5000
MLFLOW_EXPERIMENT_NAME=iris-sepal-regression
MODEL_NAME=iris_sepal_length_regressor

# Param√®tres API : retry lors du chargement du mod√®le (optionnel)
API_MODEL_LOAD_RETRIES=30
API_MODEL_LOAD_DELAY=3
```

---

## üîÅ Reset complet (soutenance)

Un script `reset.sh` est fourni pour un red√©marrage propre sans r√©sidus :

```bash
./reset.sh
```

Ce script :
1. Arr√™te et supprime les containers et volumes (`docker compose down -v`)
2. Reconstruit tous les services sans cache (`docker compose build --no-cache`)
3. D√©marre la stack (`docker compose up -d`)
4. Attend que tous les services soient pr√™ts
5. Valide les endpoints critiques

**R√©sultat** : Pipeline en √©tat vierge, pr√™t pour la d√©mo.

---

## üõ†Ô∏è D√©bogage rapide

```bash
# Voir les logs
docker compose logs -f preprocess
docker compose logs -f train
docker compose logs -f api

# Acc√©der √† la DB
docker compose exec db psql -U $POSTGRES_USER -d $POSTGRES_DB

# √âtat
docker compose ps
```

---

## ‚úÖ Checklist des livrables pour la soutenance

- Pipeline fonctionnel (conteneurs + orchestration) ‚Äî OK
- Dossier technique (architecture, choix, m√©triques, critique, r√©partition) ‚Äî √Ä r√©diger
- Support de pr√©sentation (slides + d√©monstration) ‚Äî √Ä pr√©parer

---

## Remarques et points d'am√©lioration

- Healthchecks & restart policies : envisager `restart`/`healthcheck` pour `api` et `mlflow` en production.
- Permissions du volume `mlruns` : actuellement les services √©crivent en tant que root ; durcir si requis.
- Optionnel : endpoint de reload du mod√®le √† chaud ou UI web pour soumettre la largeur depuis le navigateur.

---

**Repo** : theotime2005/data-pipeline4
